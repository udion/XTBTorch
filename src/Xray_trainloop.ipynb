{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os, sys, random\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from gen_utils import *\n",
    "from ds import *\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    lambda x : (x-x.min())/(x.max()-x.min())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = XrayDset('../data/train/', load_tfm)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=10, shuffle=True)\n",
    "\n",
    "test_set = XrayDset('../data/test/', load_tfm)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayResnet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XrayResnet, self).__init__()\n",
    "        self.C1 = torch.nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, padding=1, stride=1)\n",
    "        self.model_ft = torchvision.models.resnet18()\n",
    "        self.model_ft.avgpool = torch.nn.AvgPool2d(kernel_size=4, padding=0, stride=2)\n",
    "        self.model_ft.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512,256),\n",
    "            torch.nn.Linear(256,2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = self.C1(y)\n",
    "        for lid, layer in enumerate(list(self.model_ft.children())[:9]):\n",
    "            y = layer(y)\n",
    "        y = y.squeeze(-1).squeeze(-1)\n",
    "        y = list(self.model_ft.children())[-1](y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 ...\n",
      "train avg loss :  0.06271755615621805\n",
      "num of correct samples : 1351/2000\n",
      "test avg loss :  0.07326721698045731\n",
      "num of correct samples : 60/120\n",
      "epoch : 1 ...\n",
      "train avg loss :  0.059338306993246076\n",
      "num of correct samples : 1400/2000\n",
      "test avg loss :  0.0676892101764679\n",
      "num of correct samples : 61/120\n",
      "epoch : 2 ...\n",
      "train avg loss :  0.058202858872711656\n",
      "num of correct samples : 1415/2000\n",
      "test avg loss :  0.12421933114528656\n",
      "num of correct samples : 67/120\n",
      "epoch : 3 ...\n",
      "train avg loss :  0.05864578062295914\n",
      "num of correct samples : 1427/2000\n",
      "test avg loss :  0.06448346152901649\n",
      "num of correct samples : 70/120\n",
      "epoch : 4 ...\n",
      "train avg loss :  0.05900446000695229\n",
      "num of correct samples : 1416/2000\n",
      "test avg loss :  0.07038784821828206\n",
      "num of correct samples : 59/120\n",
      "epoch : 5 ...\n",
      "train avg loss :  0.05817401498556137\n",
      "num of correct samples : 1431/2000\n",
      "test avg loss :  0.08344009766976039\n",
      "num of correct samples : 61/120\n",
      "epoch : 6 ...\n",
      "train avg loss :  0.06073811326920986\n",
      "num of correct samples : 1338/2000\n",
      "test avg loss :  0.08184964706500371\n",
      "num of correct samples : 60/120\n",
      "epoch : 7 ...\n",
      "train avg loss :  0.05650877004861832\n",
      "num of correct samples : 1447/2000\n",
      "test avg loss :  0.11714499493439992\n",
      "num of correct samples : 61/120\n",
      "epoch : 8 ...\n",
      "train avg loss :  0.05721689310669899\n",
      "num of correct samples : 1438/2000\n",
      "test avg loss :  0.06751459489266078\n",
      "num of correct samples : 68/120\n",
      "epoch : 9 ...\n",
      "train avg loss :  0.05378749011456967\n",
      "num of correct samples : 1468/2000\n",
      "test avg loss :  0.3886776288350423\n",
      "num of correct samples : 62/120\n",
      "epoch : 10 ...\n",
      "train avg loss :  0.05626128222048283\n",
      "num of correct samples : 1443/2000\n",
      "test avg loss :  0.07389794339736303\n",
      "num of correct samples : 60/120\n",
      "epoch : 11 ...\n",
      "train avg loss :  0.05614586536586284\n",
      "num of correct samples : 1467/2000\n",
      "test avg loss :  0.07544543792804083\n",
      "num of correct samples : 60/120\n",
      "epoch : 12 ...\n",
      "train avg loss :  0.05369848504662514\n",
      "num of correct samples : 1490/2000\n",
      "test avg loss :  0.2861884832382202\n",
      "num of correct samples : 60/120\n",
      "epoch : 13 ...\n",
      "train avg loss :  0.05515766624361276\n",
      "num of correct samples : 1488/2000\n",
      "test avg loss :  0.06350944787263871\n",
      "num of correct samples : 85/120\n",
      "epoch : 14 ...\n",
      "train avg loss :  0.05372004856169224\n",
      "num of correct samples : 1492/2000\n",
      "test avg loss :  0.09167572458585103\n",
      "num of correct samples : 60/120\n",
      "epoch : 15 ...\n",
      "train avg loss :  0.053036962866783145\n",
      "num of correct samples : 1502/2000\n",
      "test avg loss :  0.08498122096061707\n",
      "num of correct samples : 60/120\n",
      "epoch : 16 ...\n",
      "train avg loss :  0.052033248834311964\n",
      "num of correct samples : 1519/2000\n",
      "test avg loss :  0.053271365662415825\n",
      "num of correct samples : 92/120\n",
      "epoch : 17 ...\n",
      "train avg loss :  0.0515506172478199\n",
      "num of correct samples : 1526/2000\n",
      "test avg loss :  0.05607864583532016\n",
      "num of correct samples : 90/120\n",
      "epoch : 18 ...\n",
      "train avg loss :  0.051056291721761224\n",
      "num of correct samples : 1527/2000\n",
      "test avg loss :  0.06070991282661756\n",
      "num of correct samples : 84/120\n",
      "epoch : 19 ...\n",
      "train avg loss :  0.05033824896812439\n",
      "num of correct samples : 1529/2000\n",
      "test avg loss :  0.07417011559009552\n",
      "num of correct samples : 71/120\n",
      "epoch : 20 ...\n",
      "train avg loss :  0.051554768405854705\n",
      "num of correct samples : 1531/2000\n",
      "test avg loss :  0.0703592543800672\n",
      "num of correct samples : 69/120\n",
      "epoch : 21 ...\n",
      "train avg loss :  0.048891099244356154\n",
      "num of correct samples : 1568/2000\n",
      "test avg loss :  0.1287349243958791\n",
      "num of correct samples : 62/120\n",
      "epoch : 22 ...\n",
      "train avg loss :  0.048134630881249904\n",
      "num of correct samples : 1577/2000\n",
      "test avg loss :  0.11479996293783187\n",
      "num of correct samples : 59/120\n",
      "epoch : 23 ...\n",
      "train avg loss :  0.0470956836938858\n",
      "num of correct samples : 1580/2000\n",
      "test avg loss :  0.044423203667004904\n",
      "num of correct samples : 101/120\n",
      "epoch : 24 ...\n",
      "train avg loss :  0.04370222555845976\n",
      "num of correct samples : 1621/2000\n",
      "test avg loss :  0.08228297928969065\n",
      "num of correct samples : 67/120\n",
      "epoch : 25 ...\n",
      "train avg loss :  0.043002913564443586\n",
      "num of correct samples : 1628/2000\n",
      "test avg loss :  0.05787607878446579\n",
      "num of correct samples : 88/120\n",
      "epoch : 26 ...\n",
      "train avg loss :  0.041270947620272634\n",
      "num of correct samples : 1662/2000\n",
      "test avg loss :  0.1012802188595136\n",
      "num of correct samples : 62/120\n",
      "epoch : 27 ...\n",
      "train avg loss :  0.040775417268276215\n",
      "num of correct samples : 1636/2000\n",
      "test avg loss :  0.0931327963868777\n",
      "num of correct samples : 63/120\n",
      "epoch : 28 ...\n",
      "train avg loss :  0.03998633767664433\n",
      "num of correct samples : 1636/2000\n",
      "test avg loss :  0.07573176523049673\n",
      "num of correct samples : 70/120\n",
      "epoch : 29 ...\n",
      "train avg loss :  0.03952148745208978\n",
      "num of correct samples : 1671/2000\n",
      "test avg loss :  0.09585244109233221\n",
      "num of correct samples : 62/120\n",
      "epoch : 30 ...\n",
      "train avg loss :  0.03814454695209861\n",
      "num of correct samples : 1680/2000\n",
      "test avg loss :  0.0491866779824098\n",
      "num of correct samples : 93/120\n",
      "epoch : 31 ...\n",
      "train avg loss :  0.03644493812695146\n",
      "num of correct samples : 1694/2000\n",
      "test avg loss :  0.04144319022695223\n",
      "num of correct samples : 98/120\n",
      "epoch : 32 ...\n",
      "train avg loss :  0.0323140356503427\n",
      "num of correct samples : 1733/2000\n",
      "test avg loss :  0.04457411306599776\n",
      "num of correct samples : 93/120\n",
      "epoch : 33 ...\n",
      "train avg loss :  0.03279694617912173\n",
      "num of correct samples : 1734/2000\n",
      "test avg loss :  0.04463042070468267\n",
      "num of correct samples : 94/120\n",
      "epoch : 34 ...\n",
      "train avg loss :  0.030585409950464965\n",
      "num of correct samples : 1757/2000\n",
      "test avg loss :  0.12354094634453455\n",
      "num of correct samples : 65/120\n",
      "epoch : 35 ...\n",
      "train avg loss :  0.03185502427443862\n",
      "num of correct samples : 1735/2000\n",
      "test avg loss :  0.05446660419305165\n",
      "num of correct samples : 96/120\n",
      "epoch : 36 ...\n",
      "train avg loss :  0.02845657342299819\n",
      "num of correct samples : 1773/2000\n",
      "test avg loss :  0.04411163926124573\n",
      "num of correct samples : 95/120\n",
      "epoch : 37 ...\n",
      "train avg loss :  0.027152320433408022\n",
      "num of correct samples : 1793/2000\n",
      "test avg loss :  0.06303632333874702\n",
      "num of correct samples : 90/120\n",
      "epoch : 38 ...\n",
      "train avg loss :  0.025842124739661812\n",
      "num of correct samples : 1805/2000\n",
      "test avg loss :  0.06353764732678731\n",
      "num of correct samples : 89/120\n",
      "epoch : 39 ...\n",
      "train avg loss :  0.022776854034513235\n",
      "num of correct samples : 1820/2000\n",
      "test avg loss :  0.0495425837735335\n",
      "num of correct samples : 95/120\n",
      "epoch : 40 ...\n",
      "train avg loss :  0.02344733216241002\n",
      "num of correct samples : 1822/2000\n",
      "test avg loss :  0.05279682464897632\n",
      "num of correct samples : 94/120\n",
      "epoch : 41 ...\n",
      "train avg loss :  0.02150924177840352\n",
      "num of correct samples : 1837/2000\n",
      "test avg loss :  0.04677747152745724\n",
      "num of correct samples : 97/120\n",
      "epoch : 42 ...\n",
      "train avg loss :  0.019568502291105686\n",
      "num of correct samples : 1858/2000\n",
      "test avg loss :  0.04764813302705685\n",
      "num of correct samples : 97/120\n",
      "epoch : 43 ...\n",
      "train avg loss :  0.019794843416661025\n",
      "num of correct samples : 1852/2000\n",
      "test avg loss :  0.04785498020549615\n",
      "num of correct samples : 95/120\n",
      "epoch : 44 ...\n",
      "train avg loss :  0.0180784985460341\n",
      "num of correct samples : 1879/2000\n",
      "test avg loss :  0.06112473445634047\n",
      "num of correct samples : 97/120\n",
      "epoch : 45 ...\n",
      "train avg loss :  0.017208391036838293\n",
      "num of correct samples : 1871/2000\n",
      "test avg loss :  0.04858622588217258\n",
      "num of correct samples : 97/120\n",
      "epoch : 46 ...\n",
      "train avg loss :  0.01773247302789241\n",
      "num of correct samples : 1871/2000\n",
      "test avg loss :  0.04961106268068154\n",
      "num of correct samples : 97/120\n",
      "epoch : 47 ...\n",
      "train avg loss :  0.01577011742442846\n",
      "num of correct samples : 1883/2000\n",
      "test avg loss :  0.05123077165335417\n",
      "num of correct samples : 99/120\n",
      "epoch : 48 ...\n",
      "train avg loss :  0.016689999839290977\n",
      "num of correct samples : 1885/2000\n",
      "test avg loss :  0.05078327227383852\n",
      "num of correct samples : 95/120\n",
      "epoch : 49 ...\n",
      "train avg loss :  0.017183891729451718\n",
      "num of correct samples : 1878/2000\n",
      "test avg loss :  0.05158144570887089\n",
      "num of correct samples : 96/120\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       No TB       0.78      0.83      0.81        60\n",
      "          TB       0.82      0.77      0.79        60\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       120\n",
      "   macro avg       0.80      0.80      0.80       120\n",
      "weighted avg       0.80      0.80      0.80       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "M = XrayResnet()\n",
    "M = M.to(device)\n",
    "optimizer = torch.optim.Adam(M.parameters(), lr=6e-4, weight_decay=1e-2)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss_track = []\n",
    "test_loss_track = []\n",
    "\n",
    "for eph in range(n_epochs):\n",
    "    print('epoch : {} ...'.format(eph))\n",
    "    n_correct = 0\n",
    "    avg_loss = 0\n",
    "    n_samples = 0\n",
    "    M.train()\n",
    "    exp_lr_scheduler.step()\n",
    "    for idx, xy in enumerate(train_loader):\n",
    "        x, y = xy\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = M(x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        n_correct += torch.sum(preds.data == y.data)\n",
    "        avg_loss += loss.item()\n",
    "        n_samples += x.size(0)\n",
    "    avg_loss = avg_loss/n_samples\n",
    "    train_loss_track.append(avg_loss)\n",
    "    print('train avg loss : ', avg_loss)\n",
    "    print('num of correct samples : {}/{}'.format(n_correct, n_samples))\n",
    "    \n",
    "    n_correct = 0\n",
    "    avg_loss = 0\n",
    "    n_samples = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    M.eval()\n",
    "    for idx, xy in enumerate(test_loader):\n",
    "        x, y = xy\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        outputs = M(x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        n_correct += torch.sum(preds.data == y.data)\n",
    "        gt_labels += list(y.data.cpu().numpy())\n",
    "        pred_labels += list(preds.data.cpu().numpy())\n",
    "        avg_loss += loss.item()\n",
    "        n_samples += x.size(0)\n",
    "    avg_loss = avg_loss/n_samples\n",
    "    test_loss_track.append(avg_loss)\n",
    "    print('test avg loss : ', avg_loss)\n",
    "    print('num of correct samples : {}/{}'.format(n_correct, n_samples))\n",
    "    \n",
    "    \n",
    "plt.plot(train_loss_track, 'b')\n",
    "plt.plot(test_loss_track, 'r')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('avg loss')\n",
    "plt.show()\n",
    "\n",
    "target_names = ['No TB', 'TB']\n",
    "print(classification_report(gt_labels, pred_labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XrayResnet(\n",
       "  (C1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (model_ft): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=4, stride=2, padding=0)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
